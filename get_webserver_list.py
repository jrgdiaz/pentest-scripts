from xml.dom import minidom
import subprocess
import sys

#example proof of concept extract links using grep
#python get_webservers_list.py
#Enter your .nessus filename
#cat webserver.list | xargs -I '{}' bash -c 'curl -v -s -k {} 2>&1 | grep --color -i "host\|href" &' > hrefs_db.txt


def get_webservers_list(nessus_xml_file):

        xmldoc = minidom.parse(nessus_xml_file)
        hosts = xmldoc.getElementsByTagName('ReportHost')
        webservers = set()
        for ip in hosts:
                ip_report_items = ip.getElementsByTagName('ReportItem')
                for report_item in ip_report_items:
                        if report_item.attributes['pluginName'].value == "Nessus SYN scanner" \
                        and \
                                (report_item.attributes['svc_name'].value =="www" or report_item.attributes['svc_name'].value=="https?" or report_item.attributes['svc_name'].value=="http?"):

                                webservers.add("http://"+ip.attributes['name'].value+":"+report_item.attributes['port'].value)
                                webservers.add("https://"+ip.attributes['name'].value+":"+report_item.attributes['port'].value)
        return webservers

x = raw_input('Enter your .nessus filename\n')
webservers = get_webservers_list(x)
for webserver in webservers:
        print(webserver)
