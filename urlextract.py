import requests, urllib.parse,argparse
from bs4 import BeautifulSoup
from termcolor import cprint

def urlextract(url):
        headers = requests.utils.default_headers()
        headers.update({'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 9_1 like Mac OS X) AppleWebKit/601.1.46 (KHTML, like Gecko) Version/9.0 Mobile/13B143 Safari/601.1 (compatible; AdsBot-Google-Mobile; +http://www.google.com/mobile/adsbot.html)'})
        response = requests.get('https://urlextractor.net/?target_url=%s&href=1&link_type=all&image=1&meta=1&extract=Extract+Links' % (urllib.parse.quote(url, safe='')),headers=headers)
        soup = BeautifulSoup(response.text,'lxml')
        links = [links['href'] for tbody in soup.find_all('tbody') for trs in tbody.find_all('tr') for tds in trs.find_all('td') for links in tds.find_all('a',href=True)]
        return links

def main():
        parser = argparse.ArgumentParser()
        parser.add_argument("-u", "--url",
                    dest="url",
                    help="Check a single URL.",
                    action='store')
        parser.add_argument("-l", "--list",
                    dest="usedlist",
                    help="Check a list of URLs.",
                    action='store')
        args = parser.parse_args()
        urls = []
        if args.url:
                urls.append(args.url)
        if args.usedlist:
            with open(args.usedlist, "r",encoding='utf-8') as f:
                for i in f.readlines():
                    i = i.strip()
                    if i == "" or i.startswith("#"):
                        continue
                    urls.append(i)
        cprint(f'[+] Gathering Links from urlextractor.net for:\n{urls}','green')
        for url in urls:
                links = urlextract(url)
                for link in links:
                        print(link)

if __name__ == "__main__":
        main()